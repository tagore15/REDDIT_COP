{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "path =r'H:\\REDDIT\\DATA\\reddit-top-2.5-million\\data' # use your path\n",
    "allFiles = glob.glob(path + \"/*.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# select 500 random files\n",
    "import random\n",
    "trainFiles = random.sample(range(len(allFiles)), 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "frame = pandas.DataFrame()\n",
    "list_ = []\n",
    "for file_ in trainFiles:\n",
    "    df = pandas.read_csv(allFiles[file_],index_col=None, header=0)\n",
    "    list_.append(df)\n",
    "frame = pandas.concat(list_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainFiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train data set\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "count_vect = CountVectorizer(stop_words='english')\n",
    "X_train_counts = count_vect.fit_transform(frame['title'])\n",
    "tf_transformer = TfidfTransformer().fit(X_train_counts)\n",
    "X_train_counts_tf = tf_transformer.transform(X_train_counts)\n",
    "X_train_out = frame['score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mse', max_depth=25, max_features=None,\n",
       "           max_leaf_nodes=None, min_impurity_split=1e-07,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "           splitter='best')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "reg = DecisionTreeRegressor(max_depth = 25)\n",
    "reg.fit(X_train_counts_tf, X_train_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "X_train_predict = reg.predict(X_train_counts_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "143011.25334969597"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(X_train_out, X_train_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# check mean squared error on 500 different subreddits than used for training\n",
    "frame_test = pandas.DataFrame()\n",
    "list_ = []\n",
    "for file_ in range(len(allFiles)):\n",
    "    if file_ not in trainFiles:\n",
    "        df = pandas.read_csv(allFiles[file_],index_col=None, header=0)\n",
    "        list_.append(df)\n",
    "    if len(list_) == 500:\n",
    "        break\n",
    "frame_test = pandas.concat(list_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_test_out = frame_test['score']\n",
    "X_test_counts = count_vect.transform(frame_test['title'])\n",
    "X_test_counts_tf = tf_transformer.transform(X_test_counts)\n",
    "X_test_predict = reg.predict(X_test_counts_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "153690.3317136321"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(X_test_out, X_test_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# utility function for predicting score of lineNum row data in fileName\n",
    "def predictScore(fileName, lineNum):\n",
    "    dfp = pandas.read_csv(fileName, index_col=None, header=0)\n",
    "    X_counts = count_vect.transform(dfp['title'])\n",
    "    X_counts_tf = tf_transformer.transform(X_counts)\n",
    "    X_predict = reg.predict(X_counts_tf)\n",
    "    return X_predict[lineNum]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "160.00704355271313"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictScore(path+\"/coding.csv\", 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nFor experimenting with GridSearch\\nfrom sklearn.grid_search import GridSearchCV\\nfrom sklearn import metrics\\nfrom sklearn.metrics import make_scorer\\nfrom sklearn.tree import DecisionTreeRegressor\\n\\nregressor = DecisionTreeRegressor()\\nparameters = {'max_depth':(10,20,25)}\\nscoring_function = make_scorer(mean_squared_error, greater_is_better = False)\\nreg = GridSearchCV(regressor, parameters, scoring_function)\\nreg.fit(X_train_counts_tf, X_train_out)\\n\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "For experimenting with GridSearch\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "regressor = DecisionTreeRegressor()\n",
    "parameters = {'max_depth':(10,20,25)}\n",
    "scoring_function = make_scorer(mean_squared_error, greater_is_better = False)\n",
    "reg = GridSearchCV(regressor, parameters, scoring_function)\n",
    "reg.fit(X_train_counts_tf, X_train_out)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\none_hot = pandas.get_dummies(pd['domain'], sparse=True)\\nhot_header_list = one_hot.columns.values.tolist()\\nin1 = pd[['over_18']+ hot_header_list]\\nout1 = pd['score']\\n\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "one_hot = pandas.get_dummies(pd['domain'], sparse=True)\n",
    "hot_header_list = one_hot.columns.values.tolist()\n",
    "in1 = pd[['over_18']+ hot_header_list]\n",
    "out1 = pd['score']\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
